{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage1_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpxvQ14HFYM1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIJwvszjF4AZ"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsmkWna44Fdc"
      },
      "source": [
        "project_path = '/content/drive/My Drive/Technical Debt/Codes/Traditional Model/'## we will store our data in this drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg0tjgVC4JKu"
      },
      "source": [
        "def clean_text(text):\n",
        "    \n",
        "    text = re.sub(r\"\\n\", \" \", text)\n",
        "    text = re.sub(r\"\\r\", \" \", text)\n",
        "    \n",
        "\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq2PZVPxP8Y5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HLkBop16E6J"
      },
      "source": [
        "\n",
        "'''\n",
        "#df_total=pd.read_excel(project_path+'R_issues_comments_list_sentence_level_labeled.xlsx')\n",
        "df_total=pd.read_excel(project_path+'R_issues_comments_list_sentence_level_labeled_New.xlsx')\n",
        "df_total = df_total[['Sentence Text','TD (Sentence Level)']]\n",
        "df_total = df_total.rename({'Sentence Text': 'text', 'TD (Sentence Level)': 'labels'}, axis='columns')\n",
        "#print(df_total)\n",
        "\n",
        "df_total['text']=df_total['text'].apply(str)\n",
        "#print(df_total)\n",
        "df_total['text']=df_total['text'].map(lambda x: clean_text(x))\n",
        "#df_total[\"labels\"] = df_total[\"labels\"].apply(lambda x: x.replace(\"REQUIREMENTS\", \"REQUIREMENT\"))\n",
        "#df_total['text'] =df_total['text'].str.lower()\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
        "\n",
        "features = tfidf.fit_transform(df_total.text).toarray()\n",
        "labels = df_total.labels'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrHt2rkuPXlY"
      },
      "source": [
        "import pickle\n",
        "train_data = pickle.load(open(project_path+\"Train_Test_Data/train_df.pkl\",\"rb\"))\n",
        "test_data = pickle.load(open(project_path+\"Train_Test_Data/test_df.pkl\",\"rb\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2PY7i_8SCKA"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#TfidfVectorizer\n",
        "\n",
        "tfidf = CountVectorizer(stop_words='english')\n",
        "\n",
        "tfidf.fit_transform(train_data.text)\n",
        "\n",
        "X_train = tfidf.transform(train_data.text).toarray()\n",
        "\n",
        "y_train = train_data.labels\n",
        "\n",
        "X_test = tfidf.transform(test_data.text).toarray()\n",
        "\n",
        "y_test = test_data.labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWl7a8j06Rf7"
      },
      "source": [
        "## models\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "models = [\n",
        "    LinearSVC()\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "  #X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"Performance of \"+model_name)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}