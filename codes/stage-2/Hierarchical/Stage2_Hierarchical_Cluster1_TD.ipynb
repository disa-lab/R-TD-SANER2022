{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage2_Hierarchical_Cluster1_TD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpxvQ14HFYM1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIJwvszjF4AZ"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCBxNisC4Ga-"
      },
      "source": [
        "!pip install simpletransformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsmkWna44Fdc"
      },
      "source": [
        "project_path = '/content/drive/My Drive/Technical Debt/Codes/Stage2/Hierarchical/'## we will store our data in this drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg0tjgVC4JKu"
      },
      "source": [
        "def clean_text(text):\n",
        "    \n",
        "    text = re.sub(r\"\\n\", \" \", text)\n",
        "    text = re.sub(r\"\\r\", \" \", text)\n",
        "\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HLkBop16E6J"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "\n",
        "df_total=pd.read_excel(project_path+'TD_dataset.xlsx')\n",
        "df_total = df_total[['Sentence Text','TD Type']]\n",
        "df_total = df_total.rename({'Sentence Text': 'text', 'TD Type': 'labels'}, axis='columns')\n",
        "df_total[\"labels\"] = df_total[\"labels\"].apply(lambda x: x.replace(\"REQUIREMENTS\", \"REQUIREMENT\"))\n",
        "\n",
        "df_total['text']=df_total['text'].map(lambda x: clean_text(x))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "user = 'USER'\n",
        "cran = 'CRAN'\n",
        "developer = 'DEVELOPER'\n",
        "\n",
        "type_parent_map = {'DOCUMENTATION':user, 'BUILD':cran, 'REQUIREMENT':user, 'ARCHITECTURE':cran, 'DESIGN':developer, 'USABILITY':user, 'CODE':developer, 'VERSIONING':cran, 'TEST':developer, 'DEFECT':developer}\n",
        "\n",
        "\n",
        "type_label_map = {'DOCUMENTATION':0, 'BUILD':-1, 'REQUIREMENT':-1, 'ARCHITECTURE':-1, 'DESIGN':1, 'USABILITY':-1, 'CODE':2, 'VERSIONING':-1, 'TEST':3, 'DEFECT':4}\n",
        "\n",
        "\n",
        "\n",
        "parent_label_map = {user:0, developer:1, cran:2}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print(type_label_map['BUILD'])\n",
        "\n",
        "df_total_label_list = df_total['labels'].tolist()\n",
        "\n",
        "df_total_label_numeric_list = []\n",
        "\n",
        "for label_type in df_total_label_list:\n",
        "  numeric_label = type_label_map[label_type]\n",
        "  df_total_label_numeric_list.append(numeric_label)\n",
        "\n",
        "df_total['labels'] = df_total_label_numeric_list\n",
        "\n",
        "del df_total_label_list\n",
        "del df_total_label_numeric_list\n",
        "\n",
        "\n",
        "df_total = df_total[df_total['labels']!=-1]\n",
        "\n",
        "num_of_TD_types = len(set(df_total['labels'].tolist()))\n",
        "\n",
        "df_train, df_test = train_test_split(df_total, test_size=0.2, random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "texts_train=[]\n",
        "texts_train=df_train['text']\n",
        "\n",
        "label_train=df_train['labels']\n",
        "\n",
        "\n",
        "X_train=texts_train.astype(str).values\n",
        "X_train=np.reshape(X_train,(-1,1))\n",
        "\n",
        "\n",
        "label_train=label_train.astype(int).values\n",
        "y_train=np.reshape(label_train,(-1,1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbfZv7wQ58vN"
      },
      "source": [
        "\n",
        "\n",
        "texts_test=[]\n",
        "texts_test=df_test['text']\n",
        "label_test=df_test['labels']\n",
        "\n",
        "\n",
        "X_test=texts_test.astype(str).values\n",
        "X_test=np.reshape(X_test,(-1,1))\n",
        "\n",
        "\n",
        "label_test=label_test.astype(int).values\n",
        "y_test=np.reshape(label_test,(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cyxuaPe4bWT"
      },
      "source": [
        "sentences = X_train[:,0]\n",
        "print(sentences[0])\n",
        "labels = y_train[:, 0]\n",
        "#labels = y_train\n",
        "print(labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33g5TEkldF8K"
      },
      "source": [
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * sentences.shape[0])\n",
        "\n",
        "x_train = sentences[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_val = sentences[-nb_validation_samples:]\n",
        "y_val = labels[-nb_validation_samples:]\n",
        "\n",
        "print(x_train[0])\n",
        "print(x_val[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fzadJpd7gaw"
      },
      "source": [
        "import pandas as pd\n",
        "ll=[]\n",
        "for i in range(len(x_train)):\n",
        "  ll.append([x_train[i],y_train[i]])\n",
        "\n",
        "train_df = pd.DataFrame(ll,columns=['text','labels'])\n",
        "\n",
        "\n",
        "ll=[]\n",
        "for i in range(len(x_val)):\n",
        "  ll.append([x_val[i],y_val[i]])\n",
        "\n",
        "val_df = pd.DataFrame(ll,columns=['text','labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frj6xSKu_w2y"
      },
      "source": [
        "sentences_test = X_test[:,0]\n",
        "print(sentences_test[0])\n",
        "labels_test = y_test[:, 0]\n",
        "#labels = y_train\n",
        "print(labels_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU-lAE0N8Uc0"
      },
      "source": [
        "ll=[]\n",
        "for i in range(len(sentences_test)):\n",
        "  ll.append([sentences_test[i],labels_test[i]])\n",
        "\n",
        "test_df = pd.DataFrame(ll,columns=['text','labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evd3WkX45UPc"
      },
      "source": [
        "model_type = \"bert\"\n",
        "model_name = \"bert-base-cased\"\n",
        "\n",
        "train_args = {\n",
        "    \"reprocess_input_data\": True,\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"use_cached_eval_features\": True,\n",
        "    \"output_dir\": project_path+\"output2/\"+model_type,\n",
        "    \"best_model_dir\": project_path+\"output2/\"+model_type+\"/best_model\",\n",
        "    \"use_early_stopping\": False,\n",
        "    \"early_stopping_delta\": 0.0,\n",
        "    \"early_stopping_metric\": \"eval_loss\",\n",
        "    \"early_stopping_metric_minimize\" : True,\n",
        "    \"early_stopping_patience\" : 2,\n",
        "    \"evaluate_during_training\": True,\n",
        "    \"max_seq_length\": 512,\n",
        "    \"num_train_epochs\": 10,\n",
        "    \"evaluate_during_training_steps\": 64,\n",
        "    \"wandb_project\": \"Fake News Liar_1 Bert\",\n",
        "    \"wandb_kwargs\": {\"name\": model_name},\n",
        "    \"save_model_every_epoch\": False,\n",
        "    \"save_eval_checkpoints\": False,\n",
        "    \"train_batch_size\": 64,\n",
        "    \"eval_batch_size\": 64,\n",
        "    \"evaluate_during_training_verbose\" : True\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cb8Nn9-65k6"
      },
      "source": [
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "#import pandas as pd\n",
        "\n",
        "train_args[\"max_seq_length\"] = 300\n",
        "train_args[\"train_batch_size\"] = 32\n",
        "train_args[\"gradient_accumulation_steps\"] = 1\n",
        "train_args[\"evaluate_during_training\"] = True\n",
        "train_args[\"evaluate_during_training_steps\"] = 256\n",
        "train_args[\"num_train_epochs\"] = 10\n",
        "train_args[\"use_early_stopping\"] = True\n",
        "\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel(model_type, model_name,num_labels=num_of_TD_types, args=train_args)\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df,eval_df=test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJhJrQnc-8T1"
      },
      "source": [
        "result, model_outputs, wrong_predictions = model.eval_model(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbTJrCnfWssH"
      },
      "source": [
        "predictions, raw_outputs = model.predict(test_df['text'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAkN1EnLzvyO"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(confusion_matrix(test_df['labels'].tolist(),predictions,labels=[0,1,2,3,4,5,6,7,8,9]))\n",
        "\n",
        "#'DOCUMENTATION':0, 'BUILD':1, 'REQUIREMENT':2, 'ARCHITECTURE':3, 'DESIGN':4, 'USABILITY':5, 'CODE':6, 'VERSIONING':7, 'TEST':8, 'DEFECT':9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tphUDGNZVIF"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbQX7gSMl-Wk"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "print(precision_recall_fscore_support(y_true, y_pred, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpseGVTBnqsu"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCKxjHpoob_T"
      },
      "source": [
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "\n",
        "\n",
        "loaded_model = ClassificationModel(\n",
        "    \"bert\", project_path + \"output2/bert/\"\n",
        ")\n",
        "\n",
        "predictions_by_loaded_model, raw_outputs_loaded_model = model.predict(test_df['text'])\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "print(accuracy_score(test_df['labels'],predictions_by_loaded_model))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}